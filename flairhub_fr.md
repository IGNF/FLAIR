---
layout: default
title: FLAIR-HUB
---

<div style="position: relative; text-align: center;">
  <a href="./flairhub.html" style="font-size: 11pt;"><b>ğŸ‡¬ğŸ‡§ English version</b></a><br>
  <img src="img/flair_bandeau.jpg" alt="" style="width: 100%; max-width: 1200px;" />
</div>
<br>


<center>
  
### ğŸŒ Sommaire

<table style="width:100%; max-width:400px; border: 2px solid red; border-radius: 12px; background-color: rgb(61, 60, 60); border-collapse: separate; border-spacing: 0;">
  <tbody style="color: #1e1e1e; font-size: 1.05em;">
    <tr><td style="border: none; padding: 10px;"></td></tr>
    <tr><td style="border: none; padding: 4px 25px;">â¡&nbsp;ğŸ”—&nbsp;<a href="#LINKS" style="color: lightgreen;"><b>Liens utiles</b></a></td></tr>
    <tr><td style="border: none; padding: 4px 25px;">â¡&nbsp;ğŸ¯&nbsp;<a href="#FIGURES" style="color: lightgreen;"><b>Chiffres clÃ©s</b></a></td></tr>
    <tr><td style="border: none; padding: 4px 25px;">â¡&nbsp;ğŸ—‚ï¸&nbsp;<a href="#MODALITIES" style="color: lightgreen;"><b>ModalitÃ©s du dataset</b></a></td></tr>
    <tr><td style="border: none; padding: 4px 25px;">â¡&nbsp;ğŸ·ï¸&nbsp;<a href="#SUPERVISION" style="color: lightgreen;"><b>Supervision</b></a></td></tr>
    <tr><td style="border: none; padding: 4px 25px;">â¡&nbsp;ğŸ§±&nbsp;<a href="#ARCHI" style="color: lightgreen;"><b>Architecture de rÃ©fÃ©rence</b></a></td></tr>
    <tr><td style="border: none; padding: 4px 25px;">â¡&nbsp;ğŸ§­&nbsp;<a href="#FLAIRs" style="color: lightgreen;"><b>DÃ©fis FLAIR prÃ©cÃ©dents</b></a></td></tr>    
    <tr><td style="border: none; padding: 10px;"></td></tr>
  </tbody>
</table>
</center>

<hr>



<center>
<table style="width:100%; max-width:1400px; border-collapse: separate; border-spacing: 0;">
  <thead>
    <tr>
      <th colspan="3" style="
        text-align: center;
        padding: 2% 15%;
        border: none;
        background-color: transparent;
        color: inherit;
        font-weight: bold;
      ">
        FLAIR-HUB intÃ¨gre et Ã©tend les jeux de donnÃ©es FLAIR#1 et FLAIR#2 pour former une ressource unifiÃ©e, Ã  grande Ã©chelle et multi-capteur, dÃ©diÃ©e Ã  lâ€™occupation du sol, avec des annotations Ã  trÃ¨s haute rÃ©solution. Couvrant plus de 2 500 kmÂ² de paysages et dâ€™Ã©co-climats variÃ©s Ã  travers la France, il contient plus de 63 milliards de pixels annotÃ©s manuellement, rÃ©partis sur 19 classes dâ€™occupation du sol et 23 classes de types de cultures.<br><br>
        Ce jeu de donnÃ©es aligne des sources complÃ©mentaires, incluant lâ€™imagerie aÃ©rienne, les satellites SPOT et Sentinel, des donnÃ©s d'Ã©lÃ©vation, ainsi que des photographies aÃ©riennes historiques, apportant une diversitÃ© spatiale, spectrale et temporelle riche. FLAIR-HUB soutient le dÃ©veloppement de mÃ©thodes de segmentation sÃ©mantique, de fusion multimodale et dâ€™apprentissage auto-supervisÃ©, et continuera dâ€™Ã©voluer avec de nouvelles modalitÃ©s et annotations.
      </th>
    </tr>
  </thead>
</table>
</center>

<p align="center"><img src="img/FLAIR-HUB_overview_dark.png" alt="" style="width:100%;max-width:900px;" /></p>




<hr><br><a id="LINKS"></a>

### ğŸ”— Liens utiles

<center>
<table style="width:100%; max-width:1200px; background-color:rgb(61, 60, 60); border: 2px solid green; border-radius: 12px; border-collapse: separate; border-spacing: 0;">
  <tbody style="color: white; font-size: 1.05em;">
    <tr><td style="border: none; padding: 4px 20px;">ğŸ“„ <a href="https://arxiv.org/pdf/2211.12979.pdf" target="_blank" style="color: lightgreen;"><b>Data Paper</b></a> â€“ Learn more about the dataset in the official publication</td></tr>
    <tr><td style="border: none; padding: 4px 20px;">ğŸ“ <a href="https://huggingface.co/datasets/IGNF/FLAIR-HUB" target="_blank" style="color: lightgreen;"><b>TÃ©lÃ©chargez le jeu de donnÃ©es jouet</b></a> â€“ Inclut toutes les modalitÃ©s dans une version allÃ©gÃ©e (accÃ¨s direct)</td></tr>
    <tr><td style="border: none; padding: 4px 20px;">ğŸ“ <a href="https://huggingface.co/datasets/IGNF/FLAIR-HUB" target="_blank" style="color: lightgreen;"><b>TÃ©lÃ©chargez le jeu de donnÃ©es complet</b></a> â€“ AccÃ©dez Ã  l'intÃ©gralitÃ© de FLAIR-HUB sur HuggingFace</td></tr>
    <tr><td style="border: none; padding: 4px 20px;">ğŸ¤– <a href="https://huggingface.co/datasets/IGNF/FLAIR-HUB" target="_blank" style="color: lightgreen;"><b>ModÃ¨les prÃ©-entraÃ®nÃ©s</b></a> â€“ Explorez les modÃ¨les dÃ©veloppÃ©s sur FLAIR-HUB</td></tr>
    <tr><td style="border: none; padding: 4px 20px;">ğŸ’» <a href="https://github.com/IGNF/FLAIR-HUB" target="_blank" style="color: lightgreen;"><b>Code source (GitHub)</b></a> â€“ Scripts d'entraÃ®nement, de prÃ©traitement et de benchmark</td></tr>
    <tr><td style="border: none; padding: 4px 20px;">âœ‰ï¸ <a href="mailto:flair@ign.fr" style="color: lightgreen;"><b>Nous contacter</b></a> â€“ flair@ign.fr â€“ Pour toute question ou proposition de collaboration !</td></tr>
  </tbody>
</table>
</center>





<br><hr>

### ğŸ“š Citation

Si vous utilisez FLAIR-HUB, veuillez citer :

```
Anatol Garioud, SÃ©bastien Giordano, Nicolas David, Nicolas Gonthier. 
FLAIR-HUB: semantic segmentation and domain adaptation dataset. (2025). 
DOI: https://doi.org/10.13140/RG.2.2.30183.73128/1
```

```bibtex
@article{ign2025flairhub,
  doi = {10.13140/RG.2.2.30183.73128/1},
  url = {https://arxiv.org/pdf/2211.12979.pdf},
  author = {Garioud, Anatol and Giordano, SÃ©bastien and David, Nicolas and Gonthier, Nicolas},
  title = {FLAIR #1: semantic segmentation and domain adaptation dataset},
  publisher = {arXiv},
  year = {2025}
}
```


<br><hr><br><a id="FIGURES"></a>



### ğŸ¯ Chiffres clÃ©s du jeu de donnÃ©es FLAIR-HUB

<br>


<center>
<table style="width:95%;max-width:600px;">

  <tbody>
    <tr><td>ğŸ—ºï¸</td><td>ROI / Surface couverte</td><td style="text-align: center">2,822 ROIs / 2,528 kmÂ²</td></tr>
    <tr><td>ğŸ›ï¸</td><td>DÃ©partements (France)</td><td style="text-align: center">74</td></tr>
    <tr><td>ğŸ§©</td><td>Patches IA (512Ã—512 px)</td><td style="text-align: center">241,100</td></tr>
    <tr><td>ğŸ–¼ï¸</td><td>Pixels annotÃ©s</td><td style="text-align: center">63.2 milliard</td></tr>
    <tr><td>ğŸ›°ï¸</td><td>Acquisitions Sentinel-2</td><td style="text-align: center">256,221</td></tr>
    <tr><td>ğŸ“¡</td><td>Acquisitions Sentinel-1</td><td style="text-align: center">532,696</td></tr>
    <tr><td>ğŸ“</td><td>Fichiers</td><td style="text-align: center">~2.5 million</td></tr>
    <tr><td>ğŸ’¾</td><td>Taille totale</td><td style="text-align: center">~750 GB</td></tr>
  </tbody>
</table>
</center>


<br><hr><br><a id="MODALITIES"></a>


### ğŸ—‚ï¸ AperÃ§u des modalitÃ©s du dataset

<br>

<center>
<table style="width:95%;max-width:600px;">
  <thead>
    <tr>
      <th>ModalitÃ©</th>
      <th>Description</th>
      <th style="text-align: center">RÃ©solution / Format</th>
      <th style="text-align: center">MÃ©tadonnÃ©es</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><strong>BD ORTHO (AERIAL_RGBI)</strong></td>
      <td>Images aÃ©riennes orthorectifiÃ©es avec 4 bandes (R, V, B, PIR).</td>
      <td style="text-align: center">20 cm, entier non signÃ© 8 bits</td>
      <td style="text-align: center">Statistiques radiomÃ©triques, dates/camÃ©ras d'acquisition</td>
    </tr>
    <tr>
      <td><strong>BD ORTHO HISTORIQUE (AERIAL-RLT_PAN)</strong></td>
      <td>Images aÃ©riennes panchromatiques historiques (1947â€“1965), rÃ©Ã©chantillonnÃ©es.</td>
      <td style="text-align: center">~40 cm, rÃ©el : 0,4â€“1,2 m, entier 8 bits</td>
      <td style="text-align: center">Dates, rÃ©fÃ©rences aux images originales</td>
    </tr>
    <tr>
      <td><strong>ELEVATION (DEM_ELEV)</strong></td>
      <td>DonnÃ©es d'Ã©lÃ©vation avec canaux MNS (surface) et MNT (terrain).</td>
      <td style="text-align: center">MNS : 20 cm, MNT : 1 m, Float32</td>
      <td style="text-align: center">Hauteur des objets via la diffÃ©rence MNSâ€“MNT</td>
    </tr>
    <tr>
      <td><strong>SPOT (SPOT_RGBI)</strong></td>
      <td>Images satellites SPOT 6-7, 4 bandes, rÃ©flectance calibrÃ©e.</td>
      <td style="text-align: center">1,6 m (rÃ©Ã©chantillonnÃ©e)</td>
      <td style="text-align: center">Dates d'acquisition, statistiques radiomÃ©triques</td>
    </tr>
    <tr>
      <td><strong>SENTINEL-2 (SENTINEL2_TS)</strong></td>
      <td>SÃ©ries temporelles annuelles avec 10 bandes spectrales, rÃ©flectance calibrÃ©e.</td>
      <td style="text-align: center">10,24 m (rÃ©Ã©chantillonnÃ©e)</td>
      <td style="text-align: center">Dates, stats radiomÃ©triques, masques nuage/neige</td>
    </tr>
    <tr>
      <td><strong>SENTINEL-1 ASC/DESC (SENTINEL1-XXX_TS)</strong></td>
      <td>SÃ©ries temporelles radar (VV, VH), rÃ©trodiffusion SAR (Ïƒ0).</td>
      <td style="text-align: center">10,24 m (rÃ©Ã©chantillonnÃ©e)</td>
      <td style="text-align: center">Statistiques par sÃ©rie ascendante/descendante</td>
    </tr>
    <tr>
      <td><strong>LABELS CoSIA (AERIAL_LABEL-COSIA)</strong></td>
      <td>Annotations de couverture du sol Ã  partir de photo-interprÃ©tation d'AERIAL_RGBI.</td>
      <td style="text-align: center">20 cm, 15 Ã  19 classes</td>
      <td style="text-align: center">AlignÃ© avec BD ORTHO, statistiques par patch</td>
    </tr>
    <tr>
      <td><strong>LABELS LPIS (ALL_LABEL-LPIS)</strong></td>
      <td>Informations sur les cultures issues des dÃ©clarations PAC, classification hiÃ©rarchique.</td>
      <td style="text-align: center">20 cm</td>
      <td style="text-align: center">AlignÃ© temporellement avec BD ORTHO, diffÃ©rences possibles avec CoSIA</td>
    </tr>
  </tbody>
</table>
</center>



<br><p align="center"><img src="img/FLAIR-INC_patches_1_VERTICAL.png" alt="" style="width:100%;max-width:1300px;" /></p>




<br><hr><br><a id="SUPERVISION"></a>

### ğŸ·ï¸ Supervision 

FLAIR-HUB propose deux sources complÃ©mentaires de supervision : une annotation Ã  haute rÃ©solution de lâ€™occupation du sol, rÃ©alisÃ©e par photo-interprÃ©tation experte Ã  partir des images aÃ©riennes RGBI. Elle offre une prÃ©cision au niveau du pixel et couvre 19 classes dâ€™occupation du sol; une annotation issue des dÃ©clarations agricoles dans le cadre de la Politique Agricole Commune (PAC). Elle est structurÃ©e en une taxonomie hiÃ©rarchique allant jusquâ€™Ã  46 classes de types de cultures. Alors que CoSIA reflÃ¨te lâ€™occupation rÃ©elle du sol visible sur les images, LPIS correspond Ã  lâ€™usage dÃ©clarÃ© des terres par les agriculteurs. Par consÃ©quent, ces deux modalitÃ©s diffÃ¨rent dans leur objectif, leur prÃ©cision gÃ©omÃ©trique, et leur alignement spatial.


<center>
<table style="width:100%; max-width:1100px;">
  <tr>
    <td style="text-align:center;">
      <img src="img/NOM_cosia_fr.png" alt="Figure 1" width="80%">
      <div><small>Occupation du sol (CoSIA)</small></div>
    </td>
    <td style="text-align:center;">
      <img src="img/NOM_lpis_fr.png" alt="Figure 2" width="87%">
      <div><small>Types de culture (RPG)</small></div>
    </td>
  </tr>
</table>
</center>






<br><hr><br><a id="ARCHI"></a>

### ğŸ§± Architecture de rÃ©fÃ©rence 

Le modÃ¨le de base, <b>FLAIR-UPerFuse</b>, est une architecture modulaire conÃ§ue pour la segmentation sÃ©mantique Ã  partir de donnÃ©es de tÃ©lÃ©dÃ©tection multi-modales et multi-temporelles. Il combine l'extraction spatiale de caractÃ©ristiques via un Swin Transformer, le traitement temporel Ã  lâ€™aide dâ€™un encodeur UTAE, un mÃ©canisme de fusion dÃ©diÃ©, et un dÃ©codeur UPerNet pour produire les cartes de segmentation. Lâ€™architecture sâ€™adapte dynamiquement en fonction des modalitÃ©s disponibles en entrÃ©e â€” quâ€™elles soient mono-temporelles ou multi-temporelles â€” et intÃ¨gre des branches auxiliaires pour amÃ©liorer la supervision et faciliter lâ€™apprentissage spÃ©cifique Ã  chaque modalitÃ©. L'entraÃ®nement repose sur une fonction de perte composite qui Ã©quilibre les contributions principales et auxiliaires selon les tÃ¢ches et les modalitÃ©s considÃ©rÃ©es.


<br><p align="center"><img src="img/FLAIR-HUB_arch_dark.png" alt="" style="width:100%;max-width:1000px;" /></p><br>




<br><hr><br><a id="FLAIRs"></a>

### ğŸ§­ DÃ©fis FLAIR prÃ©cÃ©dents

FLAIR#1 a lancÃ© le tout premier dÃ©fi Ã  grande Ã©chelle pour la cartographie de lâ€™occupation des sols Ã  partir dâ€™images aÃ©riennes Ã  trÃ¨s haute rÃ©solution (20â€¯cm), accompagnÃ©es dâ€™annotations sÃ©mantiques expertes sur 812â€¯kmÂ² de paysages franÃ§ais variÃ©s. Le jeu de donnÃ©es contenait plus de 77â€¯000 patchs annotÃ©s selon 19 classes dâ€™occupation des sols (13 utilisÃ©es pour l'entraÃ®nement) et sâ€™est concentrÃ© sur lâ€™adaptation de domaine, avec un test effectuÃ© sur des rÃ©gions et des dates dâ€™acquisition totalement inÃ©dites. Le dÃ©fi a mis en Ã©vidence la difficultÃ© de construire des modÃ¨les gÃ©nÃ©ralisables face Ã  des dÃ©calages spatio-temporels marquÃ©s. Les modÃ¨les de base Ã©taient des U-Net, Ã©tablissant une premiÃ¨re rÃ©fÃ©rence pour la segmentation sÃ©mantique inter-domaine en tÃ©lÃ©dÃ©tection.

ğŸ”— FLAIR#1 dÃ©pÃ´t code : https://github.com/IGNF/FLAIR-1 <br>
ğŸ”— FLAIR#1 datapaper  : https://arxiv.org/pdf/2211.12979.pdf

<br>

FLAIR#2 a poursuivi cet effort en intÃ©grant des sÃ©ries temporelles Sentinel-2 en plus des images aÃ©riennes, afin dâ€™aborder la fusion multimodale et lâ€™apprentissage temporel. Avec plus de 20 milliards de pixels annotÃ©s sur 817â€¯kmÂ² et 916 zones, FLAIR#2 introduit 13 classes principales et exploite des super-patchs spatio-temporels pour enrichir le contexte. Le jeu de donnÃ©es couvre 50 domaines spatiaux et intÃ¨gre plus de 51â€¯000 acquisitions Sentinel-2. Un modÃ¨le de rÃ©fÃ©rence bi-branche (U-T&T), combinant U-Net et U-TAE, a dÃ©montrÃ© lâ€™intÃ©rÃªt de fusionner texture mono-date et spectre multi-temporel. Le dÃ©fi met en avant la fusion inter-rÃ©solution, lâ€™hÃ©tÃ©rogÃ©nÃ©itÃ© capteur et lâ€™apprentissage robuste Ã  partir de donnÃ©es Ã©tiquetÃ©es parcimonieusement.

ğŸ”— FLAIR#2 dÃ©pÃ´t code : https://github.com/IGNF/FLAIR-2 <br>
ğŸ”— FLAIR#2 datapaper  : https://arxiv.org/abs/2310.13336

<br>




ğŸ–ï¸ <b>Podiums des dÃ©fis<b/>

<div style="display: flex; flex-direction: row; justify-content: center; gap: 40px; flex-wrap: wrap; font-size: 1.05em; line-height: 1.6;"> <div style="background-color: #2c2c2c; border-radius: 10px; padding: 15px 20px; border-left: 5px solid gold; min-width: 250px;"> <b>ğŸ FLAIR#1 â€“ Test</b><br> ğŸ¥‡ <b>businiao</b> â€” 0.65920<br> ğŸ¥ˆ Breizhchess â€” 0.65600<br> ğŸ¥‰ wangzhiyu918 â€” 0.64930 </div> 

<div style="background-color: #2c2c2c; border-radius: 10px; padding: 15px 20px; border-left: 5px solid silver; min-width: 250px;"> <b>ğŸ FLAIR#2 â€“ Test</b><br> ğŸ¥‡ <b>strakajk</b> â€” 0.64130<br> ğŸ¥ˆ Breizhchess â€” 0.63550<br> ğŸ¥‰ qwerty64 â€” 0.63510 </div> </div>
